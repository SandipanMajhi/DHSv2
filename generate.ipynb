{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from constants import *\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"./Data/2024_03_19_ocio_dhs-inventory-of-ai-use-cases.xlsx\", engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "            model_name = open_source_models[2],\n",
    "            groq_api_key = groq_api_key,\n",
    "            max_retries= 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_risks = {}\n",
    "\n",
    "for i in range(len(risk_classes)):\n",
    "    data_risks[risk_classes[i]] = []\n",
    "\n",
    "\n",
    "for i in range(len(risk_classes)):\n",
    "    for j in range(df.shape[0]):\n",
    "        datas = {\n",
    "                \"positive_prompt\" : None,\n",
    "                \"negative_prompt\" : None,\n",
    "                \"positive_scenario\" : None,\n",
    "                \"negative_scenario\" : None,\n",
    "                \"Use Case Name\" : None,\n",
    "                \"positive_definition_prompt\" : None,\n",
    "                \"positive_definition\" : None,\n",
    "                \"neg_score\" : None,\n",
    "                \"pos_score\" : None\n",
    "            }\n",
    "        datas['Use Case Name'] = df['Use Case Name'][j]\n",
    "        datas['positive_prompt'] = positive_concept_prompt[i] + \" \" +  df['Use Case Name'][j] + trailing_answer\n",
    "        datas['negative_prompt'] = negative_concept_prompt[i] + \" \" + df['Use Case Name'][j] + trailing_answer\n",
    "        datas['positive_definition_prompt'] = positive_definition_prompt[i]\n",
    "        data_risks[risk_classes[i]].append(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"queries.json\", \"w\") as f:\n",
    "    json.dump(data_risks, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/58 [00:00<?, ?it/s]/home/smajhi/Desktop/Work/LLM-Sokat/DHSv2/DHSv2/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "100%|██████████| 58/58 [06:44<00:00,  6.97s/it]\n",
      "100%|██████████| 58/58 [07:47<00:00,  8.05s/it]\n"
     ]
    }
   ],
   "source": [
    "#### Query Generation part ####\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "for i in range(len(risk_classes)):\n",
    "    pos_def = llm.predict(data_risks[risk_classes[i]][j]['positive_definition_prompt'])\n",
    "    for j in tqdm(range(df.shape[0])):\n",
    "        data_risks[risk_classes[i]][j][\"positive_definition\"] = pos_def\n",
    "\n",
    "        data_risks[risk_classes[i]][j][\"positive_scenario\"] = llm.predict(data_risks[risk_classes[i]][j]['positive_prompt']) \n",
    "\n",
    "        data_risks[risk_classes[i]][j][\"negative_scenario\"] = llm.predict(data_risks[risk_classes[i]][j]['negative_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"queries_answer.json\", \"w\") as f:\n",
    "    json.dump(data_risks, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58/58 [00:09<00:00,  6.37it/s]\n",
      "100%|██████████| 58/58 [00:21<00:00,  2.74it/s]\n"
     ]
    }
   ],
   "source": [
    "#### Scoring part ####\n",
    "for i in range(len(risk_classes)):\n",
    "    for j in tqdm(range(df.shape[0])):\n",
    "        source_sentence = data_risks[risk_classes[i]][j]['positive_definition']\n",
    "\n",
    "        output = query({\n",
    "            \"inputs\" : {\n",
    "                \"source_sentence\" : source_sentence,\n",
    "                \"sentences\" : [\n",
    "                    data_risks[risk_classes[i]][j]['positive_scenario'],\n",
    "                    data_risks[risk_classes[i]][j]['negative_scenario']\n",
    "                ]\n",
    "            }\n",
    "        })\n",
    "\n",
    "        data_risks[risk_classes[i]][j]['pos_score'] = output[0]\n",
    "        data_risks[risk_classes[i]][j]['neg_score'] = output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive_prompt': 'Based on the context of a use case of an AI inventory provide a scenario when that use case would be most trustworthy in the view of public and Department of Homeland Security.\\n\\nUse Case: AI Curated Synthetic Data\\nConcise answer within 50 words:',\n",
       " 'negative_prompt': 'Based on the context of a use case of an AI inventory provide a scenario when that use case would be least trustworthy in the view of public and Department of Homeland Security.\\n\\nUse Case: AI Curated Synthetic Data\\nConcise answer within 50 words:',\n",
       " 'positive_scenario': 'In a disaster relief scenario, an AI-powered inventory system that uses synthetic data to accurately predict and manage the supply chain of essential goods would be highly trustworthy. This system could help the Department of Homeland Security ensure critical resources are efficiently distributed to the public during emergencies, thus saving lives and resources.',\n",
       " 'negative_scenario': 'In a scenario where the AI-generated synthetic data fails to accurately represent diverse populations or specific security-sensitive goods, it may lead to inadequate inventory management, potentially causing public distrust and DHS concern, especially in critical infrastructure or border control situations.',\n",
       " 'Use Case Name': 'AI Curated Synthetic Data',\n",
       " 'positive_definition_prompt': 'Provide a concise definition of highly trustworthy AI inventory as viewed by public and\\nDepartment of Homeland Security.\\nDefinition of highly trustworthy AI inventory within 100 words in a single paragraph:',\n",
       " 'positive_definition': 'A highly trustworthy AI inventory, as viewed by the public and the Department of Homeland Security (DHS), can be defined as a carefully curated and transparently managed collection of artificially intelligent systems, algorithms, and technologies that have been thoroughly tested, evaluated, and validated for their reliability, safety, security, and ethical soundness. These AI systems must consistently produce accurate, unbiased, and explainable outputs, while also protecting privacy and human rights. They should be designed with robust security measures to prevent unauthorized access, tampering, and misuse. The DHS and the public place a high value on transparency in the development, deployment, and maintenance of these AI systems, and they should be held to the highest standards of accountability and regulatory compliance.',\n",
       " 'neg_score': 0.4824455678462982,\n",
       " 'pos_score': 0.627585232257843}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_risks['trustworthy'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = query({\n",
    "\t\"inputs\": {\n",
    "\t\t\"source_sentence\": \"That is a happy person\",\n",
    "\t\t\"sentences\": [\n",
    "\t\t\t\"That is a happy dog\",\n",
    "\t\t\t\"That is a very happy person\",\n",
    "\t\t\t\"Today is a sunny day\"\n",
    "\t\t]\n",
    "\t},\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6507517099380493, 0.9667371511459351, 0.4509974718093872]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputv1.json\", \"w\") as fp:\n",
    "    json.dump(data_risks, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputv1.json\", \"r\") as fp:\n",
    "    data_risks = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame.from_dict(data_risks['explainable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"explainable_score\"] = df1[\"pos_score\"] - df1[\"neg_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive_prompt               Based on the context of a use case of an AI in...\n",
       "negative_prompt               Based on the context of a use case of an AI in...\n",
       "positive_scenario             In a disaster-stricken area, Autonomous Survei...\n",
       "negative_scenario             In a scenario where Autonomous Surveillance To...\n",
       "Use Case Name                          Autonomous Surveillance Towers (Anduril)\n",
       "positive_definition_prompt    Provide a concise definition of highly explain...\n",
       "positive_definition           Highly explainable AI inventory, as viewed by ...\n",
       "neg_score                                                              0.267931\n",
       "pos_score                                                              0.528689\n",
       "Use Case ID                                                              DHS-35\n",
       "explainable_score                                                      0.260758\n",
       "Name: 14, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.loc[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In a disaster-stricken area, Autonomous Surveillance Towers by Anduril can effectively monitor and maintain inventory of critical supplies in real-time, ensuring efficient distribution and preventing thefts. This use case demonstrates transparency, accountability, and the life-saving potential of AI technology, gaining public trust and DHS approval.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.loc[14]['positive_scenario']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['positive_prompt', 'negative_prompt', 'positive_scenario',\n",
       "       'negative_scenario', 'Use Case Name', 'positive_definition_prompt',\n",
       "       'positive_definition', 'neg_score', 'pos_score', 'Use Case ID',\n",
       "       'explainable_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.merge(df2, on = [\"Use Case ID\", \"Use Case Name\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DHSv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
